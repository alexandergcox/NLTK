{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator \n",
    "\n",
    "# DA301:  Advanced Analytics for Organisational Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration video: Naive Bayes sentiment classifier using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook and accompanying video demonstration by your course convenor, Dr James Abdey, show one possible way to use the Naive Bayes classifier. To follow along with the demonstration, you will use a movie review corpus and categorise the reviews as positive or negative. This corpus is one of many useful data sets included in the NLTK library. In this video, youâ€™ll learn:\n",
    "- how to download the movie review corpus\n",
    "- how to prepare your data\n",
    "- how to apply the Naive Bayes classifier\n",
    "- how to interpret and communicate your findings.\n",
    "\n",
    "> **Note:** Your output(s) may differ from the demonstration output(s) due to the `random.shuffle()` method applied to the data and possible updates to the `movie_reviews` corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare your workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library.\n",
    "import nltk\n",
    "\n",
    "# Download the existing movie reviews.\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Costruct a list of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries.\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "\n",
    "# Construct a nested list of documents.\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Reorganise the list randomly.\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of files with negative reviews.\n",
    "negative_fileids = movie_reviews.fileids('neg')\n",
    "\n",
    "# Create a list of files with positive reviews.\n",
    "positive_fileids = movie_reviews.fileids('pos')\n",
    "\n",
    "# Display the list lengths.\n",
    "print(len(negative_fileids), len(positive_fileids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the output.\n",
    "print(movie_reviews.raw(fileids=positive_fileids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a feature extractor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object to contain the frequency distribution.\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "\n",
    "# Create a list that contains the first 2,000 words.\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "# Define a function to check whether each word is in the set of features.\n",
    "def document_features(document): \n",
    "    # Create a set of document words.\n",
    "    document_words = set(document)\n",
    "    # Create an empty dictionary of features.\n",
    "    features = {}\n",
    "    # Populate the dictionary.\n",
    "    for word in word_features:\n",
    "       # Specify whether each feature exists in the set of document words. \n",
    "       features['contains({})'.format(word)] = (word in document_words)\n",
    "    # Return the completed dictionary.\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dictionary for the first review.\n",
    "test_result = document_features(documents[0][0])\n",
    "\n",
    "for key in test_result:\n",
    "    print(key, ' : ', test_result[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of feature sets based on the documents list.\n",
    "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "\n",
    "# Assign items to the training and test sets.\n",
    "# Note the first and last 100 only.\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "\n",
    "# Create a classifier object trained on items from the training set.\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Display the accuracy score in comparison with the test set.\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Your output may differ from the demonstration output due to the `random.shuffle()` method applied to the data and possible updates to the `movie_reviews` corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the number of outputs by increasing or decreasing the number in the brackets.\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Your output may differ from the demonstration output due to the `random.shuffle()` method applied to the data and possible updates to the `movie_reviews` corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This quick demonstration shows that the Naive Bayes sentiment classifier is relatively easy to interpret. This transparency is one of the core advantages of the model. The main limitation is the assumption of independent predictors. Realistically, mostly all text is contextual and can only be understood in relation to the other text surrounding it. So remember to interpret the results with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
