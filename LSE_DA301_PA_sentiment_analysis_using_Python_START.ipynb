{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a445fa7",
   "metadata": {},
   "source": [
    "### LSE Data Analytics Online Career Accelerator \n",
    "\n",
    "# DA301:  Advanced Analytics for Organisational Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f41e48",
   "metadata": {},
   "source": [
    "## Practical activity: Sentiment analysis using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a489f",
   "metadata": {},
   "source": [
    "You are part of a data analytics team at a global company, FutureProof. The company’s product line includes a range of innovative solutions to enhance cybersecurity. The marketing manager is considering using ChatGPT to generate content, with the aim of enhancing the brand’s social media presence on YouTube and other social media platforms. The campaign will require the creation of engaging social media content, scheduled updates to social media channels, and moderating and responding to comments.  However, the CEO has reservations both about using ChatGPT, and YouTube. You have been asked to research the sentiment towards ChatGPT on YouTube. You will start by getting comments about ChatGPT straight from YouTube. To achieve this, you will need to use the YouTube API key that you created through your Google Cloud account..\n",
    "\n",
    "In this activity, you’ll pre-process and perform sentiment analysis on the extracted comments. You’ll work with the NLTK Vader class to classify words into positive, neutral, or negative. The comments will then be assigned a sentiment estimate. Therefore, you will:\n",
    "\n",
    "- access the API in Python and query YouTube for key phrases\n",
    "- customise the query and join results from the query in a Pandas DataFrame\n",
    "- apply some pre-processing and perform sentiment analysis\n",
    "- use the polarity score function and identify related words\n",
    "- visualise the output to present to the business to help them decide on whether to use ChatGPT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0275dd",
   "metadata": {},
   "source": [
    "##  1. Prepare your workstation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95272f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install the libraries.\n",
    "# !pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78308690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import googleapiclient.discovery\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Locate and read the key from your .env file.\n",
    "API_key = os.getenv('YouTube_API_key')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a36fb",
   "metadata": {},
   "source": [
    "## 2. Retrieve comments from the defined video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb18123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create an api call\n",
    "youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=API_key)\n",
    "\n",
    "# Make the search request\n",
    "comment_response = youtube.commentThreads().list(\n",
    "    part='snippet,replies',\n",
    "    maxResults=100,\n",
    "    videoId='40Kp_fa8vIw'\n",
    ").execute()\n",
    "\n",
    "# Get the comments\n",
    "\n",
    "\n",
    "# Print the comments\n",
    "for comment in comments:\n",
    "    print(comment['snippet']['topLevelComment']['snippet']['textDisplay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9bc1e3",
   "metadata": {},
   "source": [
    "## 3. Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e799e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of comments\n",
    "\n",
    "\n",
    "# Iterate over the comments and add them to the list\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "\n",
    "\n",
    "# Print the DataFrame\n",
    "\n",
    "\n",
    "# View shape of output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce567cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine values of output.\n",
    "\n",
    "\n",
    "# View results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafb873",
   "metadata": {},
   "source": [
    "## 4. Pre-processing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk and the required resources.\n",
    "\n",
    "#Create a variable to store the stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb489aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results will change every time the code is executed. Let's review the first 15.\n",
    "\n",
    "# Print the first 15 comments without stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one comment\n",
    "# Based on the results of the previous cell, select a comment in English that contains keywords suitable for text analysis\n",
    "\n",
    "# Set the index of the comment to be returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9062ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up each comment into individual words\n",
    "\n",
    "\n",
    "# View results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5086f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all english words so we can exclude anything that doesn't appear on the list.\n",
    "\n",
    "\n",
    "# View results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pre-processing:\n",
    "#-- lets get every word\n",
    "#-- lets convert it to lowercase\n",
    "#-- only include if the word is alphanumeric and if it is in the list of English words, but is not a stopword.\n",
    "\n",
    "df3 = [[y.lower() for y in x if y.lower() not in stop_words and y.isalpha() and y.lower() in all_english_words] for x in df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b0e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the same comment as above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63333700",
   "metadata": {},
   "source": [
    "## 5. Perform sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634af382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the prebuilt rules and values of the vader lexicon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82dc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the vader class SentimentIntensityAnalyser.\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create a variable sia to store the SentimentIntensityAnalyser() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5d16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through a dictionary comprehension to take every cleaned comment\n",
    "# Next run the polarity score function on the string.\n",
    "# This will return four values in a dictionary\n",
    "\n",
    "df_polarity = {\" \".join(_) : sia.polarity_scores(\" \".join(_)) for _ in df3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionary results to a Pandas DataFrame.\n",
    "# The index is the cleaned tweet.\n",
    "# We can see some of the highly positive words. \n",
    "\n",
    "\n",
    "# View the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ad95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the non-aplhanumeric words (the emojis, handles, hashtags and stopwords) removed \n",
    "# some of the most positive words are single words\n",
    "\n",
    "# Get the top 5 most positive cleaned \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00237dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 most negative words related to ChatGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d03d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe function on the compound will show the distribution and moments. \n",
    "\n",
    "polarity['compound'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ad552",
   "metadata": {},
   "source": [
    "## 6. Visualise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the best way to see is to plot. \n",
    "# In the data sampled here many of the values are 0\n",
    "# There are less negative values than positive but the negative values are highly negative.\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a boxplot. This is a good way to see how many values sit on the edges as outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a barplot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create a histogram:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c735c",
   "metadata": {},
   "source": [
    "## 7. Summarise findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a477f97",
   "metadata": {},
   "source": [
    "Type a summary of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ce42b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40611182",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6bf8c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
